# -*- coding: utf-8 -*-
import os
import cv2
import subprocess
import sys
import argparse
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from configManager import ConfigManager
from util import Util

config_manager = ConfigManager.get_instance()

class TrainSHX_data:
    def __init__(self, shx_font=None, ttf_font=None, output_dir=None, train_model=None  ):
        self.shx_font = shx_font
        self.ttf_font = ttf_font       
        # æ£€æŸ¥ output_dir æ˜¯å¦ä¸ºç©º
        if not output_dir:
            # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•ä¸ºç›¸å¯¹è·¯å¾„
            self.output_dir  = TrainSHX_data.get_default_output_dir()
        else:
            self.output_dir = output_dir
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)       
        self.train_model = train_model

    @staticmethod
    def get_default_output_dir():
        return Path(__file__).parent.parent / 'TestData' / 'ground-truth'
    
    @staticmethod  
    def is_valid_text_file(file_path):
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶ä¸”æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶ã€‚

        :param file_path: æ–‡ä»¶è·¯å¾„
        :return: å¦‚æœæ–‡ä»¶æœ‰æ•ˆä¸”ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› False
        """
        if not os.path.isfile(file_path):
            print(f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨ã€‚")
            return False

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                f.read(1024)  # å°è¯•è¯»å–å‰ 1024 å­—èŠ‚
            return True
        except (UnicodeDecodeError, IOError) as e:
            print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {file_path}ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶ã€‚")
            return False
    
    @staticmethod
    def create_training_textdata(input, output):
        if os.path.isdir(input) and os.path.isdir(output):      
            filenames = [filename for filename in os.listdir(input) if filename.endswith(".txt")]
            for filename in filenames:
                TrainSHX_data.convert_mixed_text_to_grouped_text(os.path.join(input, filename), os.path.join(output, filename))
        elif os.path.isfile(input) and os.path.isfile(output):
           TrainSHX_data.convert_mixed_text_to_grouped_text(input, output)
        else:
            print(f"æ–‡ä»¶ {input} æ— æ•ˆæˆ–ä¸æ˜¯æ–‡æœ¬æ–‡ä»¶ã€‚")
            return          
              
    @staticmethod  
    def convert_mixed_text_to_grouped_text(input_file, output_file):
        """
        å°†è¾“å…¥æ–‡ä»¶ä¸­çš„ Unicode ç¼–å·å’Œæ±‰å­—æ ¼å¼è½¬æ¢ä¸ºæ¯è¡Œ 10 ç»„ï¼Œæ¯ç»„ 5 ä¸ªæ±‰å­—çš„æ ¼å¼ã€‚
        åœ¨è¾“å‡ºæ–‡ä»¶çš„æœ€å‰é¢æ·»åŠ æŒ‡å®šçš„å­—ç¬¦é›†ï¼Œå¹¶å°†ç‰¹æ®Šå­—ç¬¦æ”¾åœ¨å•ç‹¬çš„ä¸€è¡Œã€‚
    
        :param input_file: è¾“å…¥æ–‡ä»¶åï¼ŒåŒ…å« Unicode ç¼–å·å’Œæ±‰å­—æ ¼å¼
        :param output_file: è¾“å‡ºæ–‡ä»¶åï¼Œä¿å­˜è½¬æ¢åçš„æ ¼å¼
        """
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        if not TrainSHX_data.is_valid_text_file(input_file):
            print(f"æ–‡ä»¶ {input_file} æ— æ•ˆæˆ–ä¸æ˜¯æ–‡æœ¬æ–‡ä»¶ã€‚")
            return        
    
        # æŒ‡å®šè¦æ·»åŠ çš„å­—ç¬¦é›†
        prefix_chars_numbers_letters = "0123456789\nABCDEFGHIJKLMNOPQRSTUVWXYZ\nabcdefghijklmnopqrstuvwxyz"
        prefix_chars_special = "Ã˜ âˆ  Â° Â± Ã— Ã· âˆ‘ âˆ† âˆ‡ ã¡ ã¥"
    
        # æ‰“å¼€è¾“å…¥æ–‡ä»¶è¯»å–å†…å®¹
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    
        # æ‰“å¼€è¾“å‡ºæ–‡ä»¶å‡†å¤‡å†™å…¥
        with open(output_file, 'w', encoding='utf-8') as f:
            # å†™å…¥æ•°å­—å’Œå­—æ¯
            f.write(prefix_chars_numbers_letters + '\n')
            # å†™å…¥ç‰¹æ®Šå­—ç¬¦
            f.write(prefix_chars_special + '\n\n')
    
            # ç”¨äºå­˜å‚¨æ¯è¡Œçš„æ±‰å­—
            line_content = []
            # è®¡æ•°å™¨ï¼Œç”¨äºæ§åˆ¶æ¯è¡Œçš„æ±‰å­—æ•°é‡
            count = 0
    
            # éå†æ¯ä¸€è¡Œ
            for line in lines:
                # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                if line.strip().startswith('#') or not line.strip():
                    continue
    
                # æå–æ±‰å­—
                # åˆ¤æ–­è¡Œçš„æ ¼å¼
                if '##' in line:
                    # å¤„ç† `19968:##ä¸€##` å½¢å¼
                    char = line.split('##')[1].strip()
                else:
                    # å¤„ç† `ä¸` å½¢å¼
                    char = line.strip()
                line_content.append(char)
    
                # æ¯è¡Œ10ç»„ï¼Œæ¯ç»„5ä¸ªæ±‰å­—
                if len(line_content) == 5:
                    f.write(' '.join(line_content) + ' ')
                    line_content = []
                    count += 1
    
                    # æ¯4ç»„æ¢è¡Œ
                    if count == 4:
                        f.write('\n')
                        count = 0
    
            # å¦‚æœæœ€åä¸€è¡Œä¸è¶³10ç»„ï¼Œä»ç„¶å†™å…¥
            if line_content:
                f.write(' '.join(line_content) + '\n')
    
        print("è½¬æ¢å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°", output_file)
    
    def convert_shx_to_ttf(self) -> bool:
        """é€šè¿‡å­è¿›ç¨‹è°ƒç”¨ FontForge è¿›è¡Œ SHX åˆ° TTF çš„è½¬æ¢"""
        try:
            # ç”Ÿæˆä¸´æ—¶ Python è„šæœ¬
            script_content = (
            "import fontforge\n"
            # f"font = fontforge.open(r'{self.shx_font.replace("'", r"\'")}')\n"
            # f"font.generate(r'{self.ttf_font.replace("'", r"\'")}')\n"
            )
            script_path = Path(__file__).parent / "_temp_convert.py"    
            with open(script_path, "w", encoding="utf-8") as f:
                f.write(script_content)

            # æ ¹æ®ç³»ç»Ÿç¯å¢ƒé€‰æ‹©æ‰§è¡Œæ–¹å¼
            if sys.platform == "win32":
                # Windows éœ€è¦æŒ‡å®š MSYS2 ç¯å¢ƒè·¯å¾„
                python_path = "/mingw64/bin/python"
                cmd = [
                    r"E:/msys64/usr/bin/bash.exe",
                    "-l",
                    "-c",
                    f"{python_path} {script_path.as_posix()}"
                ]
            else:
                # Linux/macOS
                cmd = ["python3", script_path]

            # æ‰§è¡Œè½¬æ¢å‘½ä»¤
            result = subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            # æ¸…ç†ä¸´æ—¶è„šæœ¬
            os.remove(script_path)

            print(f"âœ… TTF è½¬æ¢å®Œæˆ: {self.ttf_font}")
            return True

        except subprocess.CalledProcessError as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            print(f"âš ï¸ å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}")
            return False

    def generate_training_data(self):
        """ç”Ÿæˆ OCR è®­ç»ƒæ•°æ®"""
        os.makedirs(self.output_dir, exist_ok=True)
        train_texts = [
            "0123456789 ABCDEFGHIJKLMNOPQRSTUVWXYZ",
            "ç®€ä½“ä¸­æ–‡ ç¹ä½“å­— å½¢å­—ä½“ OCR è®­ç»ƒ",
            "Ã˜ âˆ  Â° Â± Ã— Ã· âˆ‘ âˆ† âˆ‡ ã¡ ã¥"
        ]

        print("ğŸš€ æ­£åœ¨ç”Ÿæˆè®­ç»ƒæ•°æ®...")
        for i, text in enumerate(train_texts):
            img = Image.new("L", (600, 100), 255)  # ç™½åº•é»‘å­—
            draw = ImageDraw.Draw(img)
            font = ImageFont.truetype(self.ttf_font, 32)

            draw.text((10, 30), text, font=font, fill=0)
            img.save(f"{self.output_dir}/sample-{i}.png")

            with open(f"{self.output_dir}/sample-{i}.gt.txt", "w", encoding="utf-8") as f:
                f.write(text)

        print("âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆï¼")

    def train_tesseract(self):
        """è®­ç»ƒ Tesseract"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒ Tesseract...")       
        
        # é…ç½®è·¯å¾„
        TESSERACT_PATH = str(Path(config_manager.get_tesseract_path()).parent)
        TESSDATA_PATH = config_manager.set_tesseract_data_path_mode("best")       
        TRAIN_DIR = r"D:/Image2CADPy/tesseract_train"  # è®­ç»ƒæ•°æ®å­˜å‚¨ç›®å½•
        FONTS_DIR = os.path.join(TRAIN_DIR, "fonts") # å­—ä½“ç›®å½•
        TRAIN_TEXT = os.path.join(TRAIN_DIR, "train_text.txt")
        MAX_ITERATIONS = 400  # è®­ç»ƒè½®æ•°

        # ç¡®ä¿è®­ç»ƒç›®å½•å­˜åœ¨
        os.makedirs(TRAIN_DIR, exist_ok=True)
        
        # æ ¡éªŒå’Œä¿æŠ¤
        Util.ensure_directory_exists(TRAIN_DIR)
        Util.ensure_directory_exists(FONTS_DIR)
        Util.ensure_file_exists(TRAIN_TEXT)        
        
         # æå–åŸºç¡€æ¨¡å‹ LSTM
        base_lstm = os.path.join(TRAIN_DIR, "chi_sim.lstm")
        subprocess.run([
            os.path.join(TESSERACT_PATH, "combine_tessdata"),
            "-e", os.path.join(TESSDATA_PATH, "chi_sim.traineddata"), base_lstm
        ])
        
        # è·å–æ‰€æœ‰ TTF å­—ä½“
        fonts = [f for f in os.listdir(FONTS_DIR) if f.endswith(".ttf")]

        for font_file in fonts:
            font_name = os.path.splitext(font_file)[0]  # è·å–å­—ä½“åç§°
            font_path = os.path.join(FONTS_DIR, font_file)

            print(f"å¼€å§‹è®­ç»ƒå­—ä½“: {font_name}...")

            output_prefix = os.path.join(TRAIN_DIR, font_name)

            # 1. ç”Ÿæˆè®­ç»ƒå›¾ç‰‡
            subprocess.run([
                os.path.join(TESSERACT_PATH, "text2image"),
                "--text", TRAIN_TEXT,
                "--outputbase", output_prefix,
                "--font", font_name,
                "--fonts_dir", FONTS_DIR,
                "--ptsize", "32"
            ])

            # 2. ç”Ÿæˆ .box æ–‡ä»¶
            subprocess.run([
                os.path.join(TESSERACT_PATH, "tesseract"),
                f"{output_prefix}.tif", output_prefix, "box.train"
            ])

            # 3. ç”Ÿæˆ LSTMF æ–‡ä»¶
            subprocess.run([
                os.path.join(TESSERACT_PATH, "tesseract"),
                f"{output_prefix}.tif", output_prefix, "lstm.train"
            ])
           
            # 4. è®­ç»ƒ LSTM
            trained_output = os.path.join(TRAIN_DIR, f"{font_name}.traineddata")
            subprocess.run([
                os.path.join(TESSERACT_PATH, "lstmtraining"),
                "--model_output", trained_output,
                "--traineddata", os.path.join(TESSDATA_PATH, "chi_sim.traineddata"),
                "--train_listfile", f"{output_prefix}.lstmf",
                "--continue_from", base_lstm,
                "--max_iterations", str(MAX_ITERATIONS)
            ])

            print(f"å­—ä½“ {font_name} è®­ç»ƒå®Œæˆï¼Œç”Ÿæˆ {trained_output}")

        print("æ‰€æœ‰å­—ä½“è®­ç»ƒå®Œæˆï¼")
    
    @staticmethod
    def generate_box_file(image_path, box_file_path, min_width=5, min_height=5):
        # è¯»å–å›¾åƒ
        image = Util.opencv_read(image_path)
        image_height = image.shape[0]
        # äºŒå€¼åŒ–å›¾åƒ
        _, thresh = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV)
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        with open(box_file_path, 'w') as f:
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                # è¿‡æ»¤æ‰å°è¾¹æ¡†
                if w >= min_width and h >= min_height:
                    # è½¬æ¢ Y åæ ‡
                    y = image_height - (y + h)

                    # å‡è®¾æ¯ä¸ªè½®å»“æ˜¯ä¸€ä¸ªå­—ç¬¦ï¼Œæ‚¨éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                    char = 'A'  # è¿™é‡Œéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„å­—ç¬¦
                    f.write(f"{char} {x} {y} {x+w} {y+h} 0\n")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="TrainSHX_data å·¥å…·")
    subparsers = parser.add_subparsers(dest='command')

    # æ·»åŠ  convert å­å‘½ä»¤
    convert_parser = subparsers.add_parser('convert_mixed_text_to_grouped_text', help='è½¬æ¢ Unicode ç¼–å·å’Œæ±‰å­—æ ¼å¼')
    convert_parser.add_argument('input_file', type=str, help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    convert_parser.add_argument('output_file', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    create_parser = subparsers.add_parser('create_training_textdata', help='åˆ›å»ºè®­ç»ƒæ•°æ®æ–‡æœ¬æ–‡ä»¶')
    create_parser.add_argument('input_dir', type=str, help='è¾“å…¥ç›®å½•è·¯å¾„')
    create_parser.add_argument('output_dir', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    create_parser = subparsers.add_parser('generate_box_file', help='åˆ›å»ºboxæ–‡ä»¶')
    create_parser.add_argument('input_file', type=str, help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    create_parser.add_argument('output_file', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    create_parser = subparsers.add_parser('train_tesseract', help='åˆ›å»ºè®­ç»ƒæ•°æ®æ–‡æœ¬æ–‡ä»¶')
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    if args.command == 'convert_mixed_text_to_grouped_text':
        TrainSHX_data.convert_mixed_text_to_grouped_text(args.input_file, args.output_file)
    elif args.command == 'create_training_textdata':
        TrainSHX_data.create_training_textdata(args.input_dir, args.output_dir)
    elif args.command == 'generate_box_file':
        TrainSHX_data.generate_box_file(args.input_file, args.output_file)
    elif args.command == 'train_tesseract':
        train_shx = TrainSHX_data()
        train_shx.train_tesseract()
    else:
        print("è¯·è¾“å…¥æ­£ç¡®çš„å‘½ä»¤")
                
                       

       

